# File containing comments

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# ğŸš€ Demo: fetch the titles of the topâ€‘5 trending GitHub repos
# ğŸ¯ Goal: showcase HTTP requests, JSON handling, and simple formatting
# ğŸ“¦ Uses only the Python standard library â€“ no extra packages needed

import json
import sys
from urllib.request import Request, urlopen


# Comment with wide string ã
def fetch_trending(limit: int = 5):
    """
    Query GitHubâ€™s public search API for the mostâ€‘starred repos.
    ğŸ‘€ Note: Unauthenticated calls have low rate limits; add a token for heavy use.
    """
    url = (
        f"https://api.github.com/search/repositories"
        f"?q=stars:>50000&sort=stars&order=desc&per_page={limit}"
    )
    headers = {"Accept": "application/vnd.github.v3+json"}
    req = Request(url, headers=headers)

    with urlopen(req) as resp:
        data = json.load(resp)

    # Extract only the fields we care about
    repos = [
        {
            "name": item["full_name"],
            "stars": item["stargazers_count"],
            "url": item["html_url"],
        }
        for item in data.get("items", [])
    ]
    return repos

def commentMain():
    # ğŸ§© Run the fetch and prettyâ€‘print the result
    repos = fetch_trending()
    if not repos:
        print("No data received.")  # âš ï¸ Simple fallback
        return

    print("\nTop trending GitHub repos:\n")
    for idx, repo in enumerate(repos, start=1):
        # ğŸ‘‰ Show rank, name, star count (with commas), and URL
        print(f"{idx}. {repo['name']} â€“ {repo['stars']:,} stars")
        print(f"   {repo['url']}\n")

    # âœ… Finished â€“ you can now extend or integrate this logic elsewhere
    # ğŸ’¡ Tip: wrap the request in a try/except block for production robustness

if __name__ == "__main__":
    # ğŸ’¡ Entryâ€‘point guard â€“ keeps imports clean when used as a module
    commentMain()